# A Comprehensive Survey on Large Language Model Based Planning

## 1 Planning Methods

### 1.1 External Module Augmented Methods

#### 1.1.1 Planner Enhanced Methods 

* **LLM+P: Empowering Large Language Models with Optimal Planning Proficiency** [![arXiv](https://img.shields.io/badge/arXiv-2023.04-red)](https://arxiv.org/abs/2304.11477) [![Code](https://img.shields.io/badge/Code-GitHub-blue)](https://github.com/Cranial-XIX/llm-pddl)
* * **LLM+ P: Empowering Large Language Models With Optimal Planning Proficiency** [![arXiv](https://img.shields.io/badge/arXiv-2023.04-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Dynamic Planning With A LLM** [![arXiv](https://img.shields.io/badge/arXiv-2023.08-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **PDDLEGO: Iterative Planning In Textual Environments** [![arXiv](https://img.shields.io/badge/arXiv-2024.05-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **PROC2PDDL: Open-Domain Planning Representations From Texts** [![arXiv](https://img.shields.io/badge/arXiv-2024.03-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Can Llms Plan Paths With Extra Hints From Solvers?** [![arXiv](https://img.shields.io/badge/arXiv-2024.10-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Robust Planning With Compound LLM Architectures: An LLM-Modulo Approach** [![arXiv](https://img.shields.io/badge/arXiv-2024.11-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **LLM+ Map: Bimanual Robot Task Planning Using Large Language Models And Planning Domain Definition Language** [![arXiv](https://img.shields.io/badge/arXiv-2025.03-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Explicit Memory Learning With Expectation Maximization** [![emnlp](https://img.shields.io/badge/emnlp-2024-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Think Before You Act: Decision Transformers With Working Memory** [![icml](https://img.shields.io/badge/icml-2023-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Synapse: Trajectory-As-Exemplar Prompting With Memory For Computer Control** [![iclr](https://img.shields.io/badge/iclr-2023-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Generative Agents: Interactive Simulacra Of Human Behavior** [![uist](https://img.shields.io/badge/uist-2023-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Memorybank: Enhancing Large Language Models With Long-Term Memory** [![arXiv](https://img.shields.io/badge/arXiv-2024-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Ldm2: A Large Decision Model Imitating Human Cognition With Dynamic Memory Enhancement** [![arXiv](https://img.shields.io/badge/arXiv-2023-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Hierarchical Planning For Complex Tasks With Knowledge Graph-Rag And Symbolic Verification** [![arXiv](https://img.shields.io/badge/arXiv-2025.04-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Z3: An Efficient Smt Solver** [![arXiv](https://img.shields.io/badge/arXiv-2008-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Cvc4** [![arXiv](https://img.shields.io/badge/arXiv-2011-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Leveraging Pre-Trained Large Language Models To Construct And Utilize World Models For Model-Based Task Planning** [![arXiv](https://img.shields.io/badge/arXiv-2023-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **PDDLEGO: Iterative Planning In Textual Environments** [![arXiv](https://img.shields.io/badge/arXiv-2024.05-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Learning Adaptive Planning Representations With Natural Language Guidance** [![arXiv](https://img.shields.io/badge/arXiv-2023-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **LLM+ P: Empowering Large Language Models With Optimal Planning Proficiency** [![arXiv](https://img.shields.io/badge/arXiv-2023.04-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Dynamic Planning With A LLM** [![arXiv](https://img.shields.io/badge/arXiv-2023.08-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Trip-Pal: Travel Planning With Guarantees By Combining Large Language Models And Automated Planners** [![arXiv](https://img.shields.io/badge/arXiv-2024.06-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Leveraging Pre-Trained Large Language Models To Construct And Utilize World Models For Model-Based Task Planning** [![arXiv](https://img.shields.io/badge/arXiv-2023-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **PDDLEGO: Iterative Planning In Textual Environments** [![arXiv](https://img.shields.io/badge/arXiv-2024.05-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Leveraging Environment Interaction For Automated PDDL Translation And Planning With Large Language Models** [![arXiv](https://img.shields.io/badge/arXiv--red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Coupling Large Language Models With Logic Programming For Robust And General Reasoning From Text** [![arXiv](https://img.shields.io/badge/arXiv-2023-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Large Language Models Can Plan Your Travels Rigorously With Formal Verification Tools** [![arXiv](https://img.shields.io/badge/arXiv-2024.04-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **To The Globe (Ttg): Towards Language-Driven Guaranteed Travel Planning** [![arXiv](https://img.shields.io/badge/arXiv-2024-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Position: Llms Canâ€™T Plan, But Can Help Planning In LLM-Modulo Frameworks** [![arXiv](https://img.shields.io/badge/arXiv--red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Robust Planning With Compound LLM Architectures: An LLM-Modulo Approach** [![arXiv](https://img.shields.io/badge/arXiv-2024.11-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Translating Natural Language To Planning Goals With Large-Language Models** [![arXiv](https://img.shields.io/badge/arXiv-2023.02-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **PROC2PDDL: Open-Domain Planning Representations From Texts** [![arXiv](https://img.shields.io/badge/arXiv-2024.03-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Planetarium: A Rigorous Benchmark For Translating Text To Structured Planning Languages** [![arXiv](https://img.shields.io/badge/arXiv-2024.07-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Autoplanbench: Automatically Generating Benchmarks For LLM Planners From PDDL** [![arXiv](https://img.shields.io/badge/arXiv-2023.11-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **A Survey On Large Language Model Based Autonomous Agents** [![arXiv](https://img.shields.io/badge/arXiv-2024-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **The Rise And Potential Of Large Language Model Based Agents: A Survey** [![arXiv](https://img.shields.io/badge/arXiv-2023.09-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Explicit Memory Learning With Expectation Maximization** [![arXiv](https://img.shields.io/badge/arXiv-2024-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Jarvis-1: Open-World Multi-Task Agents With Memory-Augmented Multimodal Language Models** [![arXiv](https://img.shields.io/badge/arXiv-2024-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Generative Agents: Interactive Simulacra Of Human Behavior** [![arXiv](https://img.shields.io/badge/arXiv-2023-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Ldm2: A Large Decision Model Imitating Human Cognition With Dynamic Memory Enhancement** [![arXiv](https://img.shields.io/badge/arXiv-2023-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Think Before You Act: Decision Transformers With Working Memory** [![arXiv](https://img.shields.io/badge/arXiv-2023-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Memorybank: Enhancing Large Language Models With Long-Term Memory** [![arXiv](https://img.shields.io/badge/arXiv-2024-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Think-In-Memory: Recalling And Post-Thinking Enable Llms With Long-Term Memory** [![arXiv](https://img.shields.io/badge/arXiv-2023.11-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Memgpt: Towards Llms As Operating Systems** [![arXiv](https://img.shields.io/badge/arXiv-2023.10-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Large Language Models Are Semi-Parametric Reinforcement Learning Agents** [![arXiv](https://img.shields.io/badge/arXiv-2024-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Mot: Memory-Of-Thought Enables Chatgpt To Self-Improve** [![arXiv](https://img.shields.io/badge/arXiv-2023-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Clin: A Continually Learning Language Agent For Rapid Task Adaptation And Generalization** [![arXiv](https://img.shields.io/badge/arXiv-2023.10-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Ghost In The Minecraft: Generally Capable Agents For Open-World Environments Via Large Language Models With Text-Based Knowledge And Memory** [![arXiv](https://img.shields.io/badge/arXiv-2023.05-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Explicit Memory Learning With Expectation Maximization** [![arXiv](https://img.shields.io/badge/arXiv-2024-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Jarvis-1: Open-World Multi-Task Agents With Memory-Augmented Multimodal Language Models** [![arXiv](https://img.shields.io/badge/arXiv-2024-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Open-Ended Instructable Embodied Agents With Memory-Augmented Large Language Models** [![arXiv](https://img.shields.io/badge/arXiv-2023-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Synapse: Trajectory-As-Exemplar Prompting With Memory For Computer Control** [![arXiv](https://img.shields.io/badge/arXiv-2023-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Jarvis-1: Open-World Multi-Task Agents With Memory-Augmented Multimodal Language Models** [![arXiv](https://img.shields.io/badge/arXiv-2024-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Synapse: Trajectory-As-Exemplar Prompting With Memory For Computer Control** [![arXiv](https://img.shields.io/badge/arXiv-2023-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Neural Turing Machines** [![arXiv](https://img.shields.io/badge/arXiv-2014.10-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **End-To-End Memory Networks** [![arXiv](https://img.shields.io/badge/arXiv-2015-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Think Before You Act: Decision Transformers With Working Memory** [![arXiv](https://img.shields.io/badge/arXiv-2023-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Exploratory Retrieval-Augmented Planning For Continual Embodied Instruction Following** [![arXiv](https://img.shields.io/badge/arXiv-2024-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Crafting Personalized Agents Through Retrieval-Augmented Generation On Editable Memory Graphs** [![arXiv](https://img.shields.io/badge/arXiv-2024-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Exploratory Retrieval-Augmented Planning For Continual Embodied Instruction Following** [![arXiv](https://img.shields.io/badge/arXiv-2024-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Learning Memory Mechanisms For Decision Making Through Demonstrations** [![arXiv](https://img.shields.io/badge/arXiv-2024.11-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **You Only Look At Screens: Multimodal Chain-Of-Action Agents** [![arXiv](https://img.shields.io/badge/arXiv-2023.09-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Multimodal Web Navigation With Instruction-Finetuned Foundation Models** [![arXiv](https://img.shields.io/badge/arXiv-2023.05-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Ask-Before-Plan: Proactive Language Agents For Real-World Planning** [![arXiv](https://img.shields.io/badge/arXiv-2024.06-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **You Only Look At Screens: Multimodal Chain-Of-Action Agents** [![arXiv](https://img.shields.io/badge/arXiv-2023.09-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Agent-Flan: Designing Data And Methods Of Effective Agent Tuning For Large Language Models** [![arXiv](https://img.shields.io/badge/arXiv-2024.03-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Training Verifiers To Solve Math Word Problems** [![arXiv](https://img.shields.io/badge/arXiv-2021.10-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Agent-Flan: Designing Data And Methods Of Effective Agent Tuning For Large Language Models** [![arXiv](https://img.shields.io/badge/arXiv-2024.03-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Fireact: Toward Language Agent Fine-Tuning** [![arXiv](https://img.shields.io/badge/arXiv-2023.10-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Opencodereasoning: Advancing Data Distillation For Competitive Coding** [![arXiv](https://img.shields.io/badge/arXiv-2025.04-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Distilling Instruction-Following Abilities Of Large Language Models With Task-Aware Curriculum Planning** [![arXiv](https://img.shields.io/badge/arXiv-2024.05-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Retrieve-Plan-Generation: An Iterative Planning And Answering Framework For Knowledge-Intensive LLM Generation** [![arXiv](https://img.shields.io/badge/arXiv-2024.06-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Selp: Generating Safe And Efficient Task Plans For Robot Agents With Large Language Models** [![arXiv](https://img.shields.io/badge/arXiv-2024.09-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Horizon-Length Prediction: Advancing Fill-In-The-Middle Capabilities For Code Generation With Lookahead Planning** [![arXiv](https://img.shields.io/badge/arXiv-2024.10-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Selp: Generating Safe And Efficient Task Plans For Robot Agents With Large Language Models** [![arXiv](https://img.shields.io/badge/arXiv-2024.09-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Cooperative Strategic Planning Enhances Reasoning Capabilities In Large Language Models** [![arXiv](https://img.shields.io/badge/arXiv-2024.10-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Enhancing Reasoning Capabilities Of Llms Via Principled Synthetic Logic Corpus** [![arXiv](https://img.shields.io/badge/arXiv-2024-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Knowagent: Knowledge-Augmented Planning For LLM-Based Agents** [![arXiv](https://img.shields.io/badge/arXiv-2024.03-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Autoact: Automatic Agent Learning From Scratch Via Self-Planning** [![arXiv](https://img.shields.io/badge/arXiv-2024.01-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Learning To Plan For Retrieval-Augmented Large Language Models From Knowledge Graphs** [![arXiv](https://img.shields.io/badge/arXiv-2024.06-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Adapting LLM Agents With Universal Feedback In Communication** [![arXiv](https://img.shields.io/badge/arXiv-2024-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Knowagent: Knowledge-Augmented Planning For LLM-Based Agents** [![arXiv](https://img.shields.io/badge/arXiv-2024.03-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Autoact: Automatic Agent Learning From Scratch Via Self-Planning** [![arXiv](https://img.shields.io/badge/arXiv-2024.01-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Stream Of Search (Sos): Learning To Search In Language** [![arXiv](https://img.shields.io/badge/arXiv-2024.04-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Dualformer: Controllable Fast And Slow Thinking By Learning With Randomized Reasoning Traces** [![arXiv](https://img.shields.io/badge/arXiv-2024.10-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Monte Carlo Tree Search Boosts Reasoning Via Iterative Preference Learning** [![arXiv](https://img.shields.io/badge/arXiv-2024.05-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Dualformer: Controllable Fast And Slow Thinking By Learning With Randomized Reasoning Traces** [![arXiv](https://img.shields.io/badge/arXiv-2024.10-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Beyond A*: Better Planning With Transformers Via Search Dynamics Bootstrapping** [![arXiv](https://img.shields.io/badge/arXiv-2024.02-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Synatra: Turning Indirect Knowledge Into Direct Demonstrations For Digital Agents At Scale** [![arXiv](https://img.shields.io/badge/arXiv-2024.09-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Learning To Plan Long-Term For Language Modeling** [![arXiv](https://img.shields.io/badge/arXiv-2024.09-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Agentgen: Enhancing Planning Abilities For Large Language Model Based Agent Via Environment And Task Generation** [![arXiv](https://img.shields.io/badge/arXiv-2024.08-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Self-Improvement Towards Pareto Optimality: Mitigating Preference Conflicts In Multi-Objective Alignment** [![arXiv](https://img.shields.io/badge/arXiv-2025.02-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Mixture-Of-Agents Enhances Large Language Model Capabilities** [![arXiv](https://img.shields.io/badge/arXiv-2024.06-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Camphor: Collaborative Agents For Multi-Input Planning And High-Order Reasoning On Device** [![arXiv](https://img.shields.io/badge/arXiv-2024.10-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Agent Planning With World Knowledge Model** [![arXiv](https://img.shields.io/badge/arXiv-2024-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **A Real-World Webagent With Planning, Long Context Understanding, And Program Synthesis** [![arXiv](https://img.shields.io/badge/arXiv-2023.07-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Mixture-Of-Agents Enhances Large Language Model Capabilities** [![arXiv](https://img.shields.io/badge/arXiv-2024.06-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Camphor: Collaborative Agents For Multi-Input Planning And High-Order Reasoning On Device** [![arXiv](https://img.shields.io/badge/arXiv-2024.10-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Closed-Loop Long-Horizon Robotic Planning Via Equilibrium Sequence Modeling** [![arXiv](https://img.shields.io/badge/arXiv-2024.10-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Autowebglm: A Large Language Model-Based Web Navigating Agent** [![arXiv](https://img.shields.io/badge/arXiv-2024-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Agent Planning With World Knowledge Model** [![arXiv](https://img.shields.io/badge/arXiv-2024-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Self-Playing Adversarial Language Game Enhances LLM Reasoning** [![arXiv](https://img.shields.io/badge/arXiv-2024.04-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Mastering Chess And Shogi By Self-Play With A General Reinforcement Learning Algorithm** [![arXiv](https://img.shields.io/badge/arXiv-2017.12-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Advancing LLM Reasoning Generalists With Preference Trees** [![arXiv](https://img.shields.io/badge/arXiv-2024.04-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Language Models Can Teach Themselves To Program Better** [![arXiv](https://img.shields.io/badge/arXiv-2022.07-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **React Meets Actre: When Language Agents Enjoy Training Data Autonomy.** [![arXiv](https://img.shields.io/badge/arXiv-2024-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Trial And Error: Exploration-Based Trajectory Optimization For LLM Agents** [![arXiv](https://img.shields.io/badge/arXiv-2024.03-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Llms In The Imaginarium: Tool Learning Through Simulated Trial And Error** [![arXiv](https://img.shields.io/badge/arXiv-2024.03-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Can LLM Be A Good Path Planner Based On Prompt Engineering? Mitigating The Hallucination For Path Planning** [![arXiv](https://img.shields.io/badge/arXiv-2024.08-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Think Smarter Not Harder: Adaptive Reasoning With Inference Aware Optimization** [![arXiv](https://img.shields.io/badge/arXiv-2025.01-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Boost, Disentangle, And Customize: A Robust System2-To-System1 Pipeline For Code Generation** [![arXiv](https://img.shields.io/badge/arXiv-2025.02-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Beyond Human Data: Scaling Self-Training For Problem-Solving With Language Models** [![arXiv](https://img.shields.io/badge/arXiv-2023.12-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Training Language Models To Self-Correct Via Reinforcement Learning, 2024** [![arXiv](https://img.shields.io/badge/arXiv--red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Flow Of Reasoning: Training Llms For Divergent Problem Solving With Minimal Examples** [![arXiv](https://img.shields.io/badge/arXiv-2024.06-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Webrl: Training LLM Web Agents Via Self-Evolving Online Curriculum Reinforcement Learning** [![arXiv](https://img.shields.io/badge/arXiv-2024.11-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Training Language Models To Self-Correct Via Reinforcement Learning, 2024** [![arXiv](https://img.shields.io/badge/arXiv--red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Rest-Mcts*: LLM Self-Training Via Process Reward Guided Tree Search** [![arXiv](https://img.shields.io/badge/arXiv-2024.06-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Q*: Improving Multi-Step Reasoning For Llms With Deliberative Planning** [![arXiv](https://img.shields.io/badge/arXiv-2024.06-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Learning Planning-Based Reasoning By Trajectories Collection And Process Reward Synthesizing** [![arXiv](https://img.shields.io/badge/arXiv-2024.02-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Gui-R1: A Generalist R1-Style Vision-Language Action Model For Gui Agents** [![arXiv](https://img.shields.io/badge/arXiv-2025.04-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Ui-R1: Enhancing Action Prediction Of Gui Agents By Reinforcement Learning** [![arXiv](https://img.shields.io/badge/arXiv-2025.03-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Infigui-R1: Advancing Multimodal Gui Agents From Reactive Actors To Deliberative Reasoners** [![arXiv](https://img.shields.io/badge/arXiv-2025.04-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Gui-R1: A Generalist R1-Style Vision-Language Action Model For Gui Agents** [![arXiv](https://img.shields.io/badge/arXiv-2025.04-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Infigui-R1: Advancing Multimodal Gui Agents From Reactive Actors To Deliberative Reasoners** [![arXiv](https://img.shields.io/badge/arXiv-2025.04-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Embodied-R: Collaborative Framework For Activating Embodied Spatial Reasoning In Foundation Models Via Reinforcement Learning** [![arXiv](https://img.shields.io/badge/arXiv-2025.04-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Retool: Reinforcement Learning For Strategic Tool Use In Llms** [![arXiv](https://img.shields.io/badge/arXiv-2025.04-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Toolrl: Reward Is All Tool Learning Needs** [![arXiv](https://img.shields.io/badge/arXiv-2025.04-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Otc: Optimal Tool Calls Via Reinforcement Learning** [![arXiv](https://img.shields.io/badge/arXiv-2025.04-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Retool: Reinforcement Learning For Strategic Tool Use In Llms** [![arXiv](https://img.shields.io/badge/arXiv-2025.04-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Alphamaze: Enhancing Large Language Models' Spatial Intelligence Via Grpo** [![arXiv](https://img.shields.io/badge/arXiv-2025.02-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Swe-Rl: Advancing LLM Reasoning Via Reinforcement Learning On Open Software Evolution** [![arXiv](https://img.shields.io/badge/arXiv-2025.02-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Self-Play Fine-Tuning Converts Weak Language Models To Strong Language Models** [![arXiv](https://img.shields.io/badge/arXiv-2024.01-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Learn Beyond The Answer: Training Language Models With Reflection For Mathematical Reasoning** [![arXiv](https://img.shields.io/badge/arXiv-2024.06-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Self-Play Preference Optimization For Language Model Alignment** [![arXiv](https://img.shields.io/badge/arXiv-2024.05-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Chain Of Preference Optimization: Improving Chain-Of-Thought Reasoning In Llms** [![arXiv](https://img.shields.io/badge/arXiv-2024.06-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Cpl: Critical Plan Step Learning Boosts LLM Generalization In Reasoning Tasks** [![arXiv](https://img.shields.io/badge/arXiv-2024.09-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Enhancing LLM Reasoning Via Critique Models With Test-Time And Training-Time Supervision** [![arXiv](https://img.shields.io/badge/arXiv-2024.11-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Thinking Llms: General Instruction Following With Thought Generation** [![arXiv](https://img.shields.io/badge/arXiv-2024.10-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Error Classification Of Large Language Models On Math Word Problems: A Dynamically Adaptive Framework** [![arXiv](https://img.shields.io/badge/arXiv-2025.01-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Rada: Retrieval-Augmented Web Agent Planning With Llms** [![arXiv](https://img.shields.io/badge/arXiv-2024-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Meta-Task Planning For Language Agents** [![arXiv](https://img.shields.io/badge/arXiv-2024.05-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Agent-Oriented Planning In Multi-Agent Systems (2024)** [![arXiv](https://img.shields.io/badge/arXiv--red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Deductive Additivity For Planning Of Natural Language Proofs** [![arXiv](https://img.shields.io/badge/arXiv-2023.07-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Paradise: Evaluating Implicit Planning Skills Of Language Models With Procedural Warnings And Tips Dataset** [![arXiv](https://img.shields.io/badge/arXiv-2024.03-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Optimizing Chain-Of-Thought Reasoning: Tackling Arranging Bottleneck Via Plan Augmentation** [![arXiv](https://img.shields.io/badge/arXiv-2024.10-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Hierarchical Planning For Complex Tasks With Knowledge Graph-Rag And Symbolic Verification** [![arXiv](https://img.shields.io/badge/arXiv-2025.04-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Least-To-Most Prompting Enables Complex Reasoning In Large Language Models** [![arXiv](https://img.shields.io/badge/arXiv-2022.05-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Protrix: Building Models For Planning And Reasoning Over Tables With Sentence Context** [![arXiv](https://img.shields.io/badge/arXiv-2024-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Hugginggpt: Solving Ai Tasks With Chatgpt And Its Friends In Hugging Face** [![arXiv](https://img.shields.io/badge/arXiv-2023-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Urbanllm: Autonomous Urban Activity Planning And Management With Large Language Models** [![arXiv](https://img.shields.io/badge/arXiv-2024.06-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Agent-Oriented Planning In Multi-Agent Systems (2024)** [![arXiv](https://img.shields.io/badge/arXiv--red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Hugginggpt: Solving Ai Tasks With Chatgpt And Its Friends In Hugging Face** [![arXiv](https://img.shields.io/badge/arXiv-2023-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Urbanllm: Autonomous Urban Activity Planning And Management With Large Language Models** [![arXiv](https://img.shields.io/badge/arXiv-2024.06-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Thoughts To Target: Enhance Planning For Target-Driven Conversation** [![arXiv](https://img.shields.io/badge/arXiv-2024-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Agent-Oriented Planning In Multi-Agent Systems (2024)** [![arXiv](https://img.shields.io/badge/arXiv--red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Plan-Rag: Planning-Guided Retrieval Augmented Generation** [![arXiv](https://img.shields.io/badge/arXiv-2024-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Distilling Script Knowledge From Large Language Models For Constrained Language Planning** [![arXiv](https://img.shields.io/badge/arXiv-2023.05-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **A Human-Like Reasoning Framework For Multi-Phases Planning Task With Large Language Models** [![arXiv](https://img.shields.io/badge/arXiv-2024.05-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Distilling Script Knowledge From Large Language Models For Constrained Language Planning** [![arXiv](https://img.shields.io/badge/arXiv-2023.05-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Rada: Retrieval-Augmented Web Agent Planning With Llms** [![arXiv](https://img.shields.io/badge/arXiv-2024-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **A Human-Like Reasoning Framework For Multi-Phases Planning Task With Large Language Models** [![arXiv](https://img.shields.io/badge/arXiv-2024.05-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Interpretable Math Word Problem Solution Generation Via Step-By-Step Planning** [![arXiv](https://img.shields.io/badge/arXiv-2023.06-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Oscar: Operating System Control Via State-Aware Reasoning And Re-Planning** [![arXiv](https://img.shields.io/badge/arXiv-2024.10-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Msi-Agent: Incorporating Multi-Scale Insight Into Embodied Agents For Superior Planning And Decision-Making** [![arXiv](https://img.shields.io/badge/arXiv-2024.09-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Interpretable Math Word Problem Solution Generation Via Step-By-Step Planning** [![arXiv](https://img.shields.io/badge/arXiv-2023.06-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Verilogcoder: Autonomous Verilog Coding Agents With Graph-Based Planning And Abstract Syntax Tree (Ast)-Based Waveform Tracing Tool** [![arXiv](https://img.shields.io/badge/arXiv-2025-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Can We Further Elicit Reasoning In Llms? Critic-Guided Planning With Retrieval-Augmentation For Solving Challenging Tasks** [![arXiv](https://img.shields.io/badge/arXiv-2024.10-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Oscar: Operating System Control Via State-Aware Reasoning And Re-Planning** [![arXiv](https://img.shields.io/badge/arXiv-2024.10-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Personal Large Language Model Agents: A Case Study On Tailored Travel Planning** [![arXiv](https://img.shields.io/badge/arXiv-2024-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Strength Lies In Differences! Improving Strategy Planning For Non-Collaborative Dialogues Via Diversified User Simulation** [![arXiv](https://img.shields.io/badge/arXiv-2024.03-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Adapt: As-Needed Decomposition And Planning With Language Models** [![arXiv](https://img.shields.io/badge/arXiv-2023.11-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Travelagent: An Ai Assistant For Personalized Travel Planning** [![arXiv](https://img.shields.io/badge/arXiv-2024.09-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Thinking, Fast And Slow** [![arXiv](https://img.shields.io/badge/arXiv-2011-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **The Empirical Case For Two Systems Of Reasoning.** [![arXiv](https://img.shields.io/badge/arXiv-1996-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Who Is Rational?: Studies Of Individual Differences In Reasoning** [![arXiv](https://img.shields.io/badge/arXiv-1999-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Flow-Of-Options: Diversified And Improved LLM Reasoning By Thinking Through Options** [![arXiv](https://img.shields.io/badge/arXiv-2025.02-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Tree Of Thoughts: Deliberate Problem Solving With Large Language Models** [![arXiv](https://img.shields.io/badge/arXiv-2023-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Search-In-The-Chain: Interactively Enhancing Large Language Models With Search For Knowledge-Intensive Tasks** [![arXiv](https://img.shields.io/badge/arXiv-2024-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Tree-Planner: Efficient Close-Loop Task Planning With Large Language Models** [![arXiv](https://img.shields.io/badge/arXiv-2023.10-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Graph Of Thoughts: Solving Elaborate Problems With Large Language Models** [![arXiv](https://img.shields.io/badge/arXiv-2024-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Thought Propagation: An Analogical Approach To Complex Reasoning With Large Language Models** [![arXiv](https://img.shields.io/badge/arXiv-2023.10-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Tree Of Thoughts: Deliberate Problem Solving With Large Language Models** [![arXiv](https://img.shields.io/badge/arXiv-2023-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Search-In-The-Chain: Interactively Enhancing Large Language Models With Search For Knowledge-Intensive Tasks** [![arXiv](https://img.shields.io/badge/arXiv-2024-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Avis: Autonomous Visual Information Seeking With Large Language Model Agent** [![arXiv](https://img.shields.io/badge/arXiv-2023-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Toolllm: Facilitating Large Language Models To Master 16000+ Real-World Apis** [![arXiv](https://img.shields.io/badge/arXiv-2023.07-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Tree-Planner: Efficient Close-Loop Task Planning With Large Language Models** [![arXiv](https://img.shields.io/badge/arXiv-2023.10-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Algorithm Of Thoughts: Enhancing Exploration Of Ideas In Large Language Models** [![arXiv](https://img.shields.io/badge/arXiv-2023.08-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Tree-Planner: Efficient Close-Loop Task Planning With Large Language Models** [![arXiv](https://img.shields.io/badge/arXiv-2023.10-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **System-1. X: Learning To Balance Fast And Slow Planning With Language Models** [![arXiv](https://img.shields.io/badge/arXiv-2024.07-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Graph Of Thoughts: Solving Elaborate Problems With Large Language Models** [![arXiv](https://img.shields.io/badge/arXiv-2024-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Adaptive Graph Of Thoughts: Test-Time Adaptive Reasoning Unifying Chain, Tree, And Graph Structures** [![arXiv](https://img.shields.io/badge/arXiv-2025.02-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Step Back To Leap Forward: Self-Backtracking For Boosting Reasoning Of Language Models** [![arXiv](https://img.shields.io/badge/arXiv-2025.02-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Codetree: Agent-Guided Tree Search For Code Generation With Large Language Models** [![arXiv](https://img.shields.io/badge/arXiv-2024.11-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Graph Of Thoughts: Solving Elaborate Problems With Large Language Models** [![arXiv](https://img.shields.io/badge/arXiv-2024-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Thought Propagation: An Analogical Approach To Complex Reasoning With Large Language Models** [![arXiv](https://img.shields.io/badge/arXiv-2023.10-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Tree-Planner: Efficient Close-Loop Task Planning With Large Language Models** [![arXiv](https://img.shields.io/badge/arXiv-2023.10-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Adaptive Graph Of Thoughts: Test-Time Adaptive Reasoning Unifying Chain, Tree, And Graph Structures** [![arXiv](https://img.shields.io/badge/arXiv-2025.02-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Efficient Selectivity And Backup Operators In Monte-Carlo Tree Search** [![arXiv](https://img.shields.io/badge/arXiv-2006-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Bandit Based Monte-Carlo Planning** [![arXiv](https://img.shields.io/badge/arXiv-2006-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Large Language Models As Commonsense Knowledge For Large-Scale Task Planning** [![arXiv](https://img.shields.io/badge/arXiv-2023-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Language Agent Tree Search Unifies Reasoning Acting And Planning In Language Models** [![arXiv](https://img.shields.io/badge/arXiv-2023.10-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Alphamath Almost Zero: Process Supervision Without Process** [![arXiv](https://img.shields.io/badge/arXiv-2024.05-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Doubly Robust Monte Carlo Tree Search** [![arXiv](https://img.shields.io/badge/arXiv-2025.02-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Large Language Models As Commonsense Knowledge For Large-Scale Task Planning** [![arXiv](https://img.shields.io/badge/arXiv-2023-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Thoughtsculpt: Reasoning With Intermediate Revision And Search** [![arXiv](https://img.shields.io/badge/arXiv-2024.04-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Monte Carlo Planning With Large Language Model For Text-Based Games** [![arXiv](https://img.shields.io/badge/arXiv--red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Coat: Chain-Of-Associated-Thoughts Framework For Enhancing Large Language Models Reasoning** [![arXiv](https://img.shields.io/badge/arXiv-2025.02-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Webpilot: A Versatile And Autonomous Multi-Agent System For Web Task Execution With Strategic Exploration** [![arXiv](https://img.shields.io/badge/arXiv-2024.08-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **A Formal Basis For The Heuristic Determination Of Minimum Cost Paths** [![arXiv](https://img.shields.io/badge/arXiv-1968-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Toolchain*: Efficient Action Space Navigation In Large Language Models With A* Search** [![arXiv](https://img.shields.io/badge/arXiv-2023.10-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Tree Search For Language Model Agents** [![arXiv](https://img.shields.io/badge/arXiv-2024.07-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **LLM-A*: Large Language Model Enhanced Incremental Heuristic Search On Path Planning** [![arXiv](https://img.shields.io/badge/arXiv-2024.07-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Beyond A*: Better Planning With Transformers Via Search Dynamics Bootstrapping** [![arXiv](https://img.shields.io/badge/arXiv-2024.02-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Dualformer: Controllable Fast And Slow Thinking By Learning With Randomized Reasoning Traces** [![arXiv](https://img.shields.io/badge/arXiv-2024.10-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **World Models** [![arXiv](https://img.shields.io/badge/arXiv-2018.03-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Deep Learning, Reinforcement Learning, And World Models** [![arXiv](https://img.shields.io/badge/arXiv-2022-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Reasoning With Language Model Is Planning With World Model** [![arXiv](https://img.shields.io/badge/arXiv-2023.05-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Is Your LLM Secretly A World Model Of The Internet? Model-Based Planning For Web Agents** [![arXiv](https://img.shields.io/badge/arXiv-2024.11-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Reflective Planning: Vision-Language Models For Multi-Stage Long-Horizon Robotic Manipulation** [![arXiv](https://img.shields.io/badge/arXiv-2025.02-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Worldcoder, A Model-Based LLM Agent: Building World Models By Writing Code And Interacting With The Environment** [![arXiv](https://img.shields.io/badge/arXiv-2025-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Reasonplanner: Enhancing Autonomous Planning In Dynamic Environments With Temporal Knowledge Graphs And Llms** [![arXiv](https://img.shields.io/badge/arXiv-2024.10-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Solving Math Word Problems With Process-And Outcome-Based Feedback** [![arXiv](https://img.shields.io/badge/arXiv-2022.11-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Let'S Verify Step By Step** [![arXiv](https://img.shields.io/badge/arXiv-2023-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Qlass: Boosting Language Agent Inference Via Q-Guided Stepwise Search** [![arXiv](https://img.shields.io/badge/arXiv-2025.02-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Scaling Autonomous Agents Via Automatic Reward Modeling And Planning** [![arXiv](https://img.shields.io/badge/arXiv-2025.02-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Speech And Language Processing: An Introduction To Natural Language Processing, Computational Linguistics, And Speech Recognition** [![arXiv](https://img.shields.io/badge/arXiv--red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Sequence Transduction With Recurrent Neural Networks** [![arXiv](https://img.shields.io/badge/arXiv-2012.11-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Self-Evaluation Guided Beam Search For Reasoning** [![arXiv](https://img.shields.io/badge/arXiv-2024-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Chain-Of-Thought Reasoning Without Prompting** [![arXiv](https://img.shields.io/badge/arXiv-2024.02-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Flap: Flow-Adhering Planning With Constrained Decoding In Llms** [![arXiv](https://img.shields.io/badge/arXiv-2024-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Non-Myopic Generation Of Language Model For Reasoning And Planning** [![arXiv](https://img.shields.io/badge/arXiv-2024-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Self-Evaluation Guided Beam Search For Reasoning** [![arXiv](https://img.shields.io/badge/arXiv-2024-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Chain-Of-Thought Reasoning Without Prompting** [![arXiv](https://img.shields.io/badge/arXiv-2024.02-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Chain-Of-Thought Prompting Elicits Reasoning In Large Language Models** [![arXiv](https://img.shields.io/badge/arXiv-2022-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Don'T Throw Away Your Value Model! Generating More Preferable Text With Value-Guided Monte-Carlo Tree Search Decoding** [![arXiv](https://img.shields.io/badge/arXiv-2024-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Flap: Flow-Adhering Planning With Constrained Decoding In Llms** [![arXiv](https://img.shields.io/badge/arXiv-2024-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Non-Myopic Generation Of Language Model For Reasoning And Planning** [![arXiv](https://img.shields.io/badge/arXiv-2024-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Contrastive Decoding Improves Reasoning In Large Language Models** [![arXiv](https://img.shields.io/badge/arXiv-2023.09-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()
* **Grounded Decoding: Guiding Text Generation With Grounded Models For Embodied Agents** [![arXiv](https://img.shields.io/badge/arXiv-2024-red)]() [![Code](https://img.shields.io/badge/Code-GitHub-blue)]()

